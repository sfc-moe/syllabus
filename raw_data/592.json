{"id":592,"name":"研究会Ａ / SEMINAR A","account_id":1,"uuid":"oDeoUqBjQOT55IRatrIoE1A6AO1GNJasJT1UR5tV","start_at":null,"grading_standard_id":null,"is_public":false,"created_at":"2020-10-01T04:39:56Z","syllabus_body":"\u003ctable style=\"width: 100%; margin: 0; border-collapse: collapse; background-color: #394B58; color: white;\" border=\"1\"\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n        \u003ctd style=\"width: 50%;\"\u003e\n          A1101\u003cbr\u003e\n          研究会Ａ\u003cbr\u003e\n          \u003cspan style=\"color: #c9c9c9;\"\u003eSEMINAR A\u003c/span\u003e\n        \u003c/td\u003e\n        \u003ctd\u003e\n          研究プロジェクト科目\u003cbr\u003e\n          \u003cspan style=\"color: #c9c9c9;\"\u003eResearch Seminars\u003c/span\u003e\u003cbr\u003e\n          4 単位\n        \u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\n\u003ch4 style=\"background-color: #ccecff; padding-left: 8px; margin-top: 0; font-weight: bold;\"\u003e\n  ソーシャルクラウドロボティクス −共生・協働するロボットから共に発達するロボットへ−\u003cbr\u003e\n  Social Cloud Robotics - from symbiotic and cooperative robots to robots that develop together -\n\u003c/h4\u003e\n\n\u003ctable style=\"width: 100%; margin: 0; border-collapse: collapse; border: 1px solid #C7CDD1;\" border=\"1\"\u003e\n  \u003ctbody\u003e\n    \u003ctr\u003e\n      \u003ctd style=\"width: 25%; background-color: #F5F5F5; border-color: #C7CDD1;\"\u003e開催日程\u003c/td\u003e\n      \u003ctd style=\"border-color: #C7CDD1;\"\u003e秋学期 火曜日５時限,木曜日６時限\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003ctd style=\"background-color: #F5F5F5; border-color: #C7CDD1;\"\u003e担当教員\u003c/td\u003e\n      \u003ctd style=\"border-color: #C7CDD1;\"\u003e高汐 一紀（タカシオ カズノリ）\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003ctd style=\"background-color: #F5F5F5; border-color: #C7CDD1;\"\u003e関連科目\u003c/td\u003e\n      \u003ctd style=\"border-color: #C7CDD1;\"\u003e\n          前提科目（関連）: B6136,B6046,B6139,C2097,B6100\u003cbr\u003e\n      \u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003ctd style=\"background-color: #F5F5F5; border-color: #C7CDD1;\"\u003e授業形態\u003c/td\u003e\n      \u003ctd style=\"border-color: #C7CDD1;\"\u003eディスカッション、グループワーク、実験、演習\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003ctd style=\"background-color: #F5F5F5; border-color: #C7CDD1;\"\u003e履修者制限\u003c/td\u003e\n      \u003ctd style=\"border-color: #C7CDD1;\"\u003e\n      \u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003ctd style=\"background-color: #F5F5F5; border-color: #C7CDD1;\"\u003e履修条件\u003c/td\u003e\n      \u003ctd style=\"border-color: #C7CDD1;\"\u003e\n        \u003cp\u003e\u003c/p\u003e\n        \u003cp style=\"color: #856a5d;\"\u003e\u003c/p\u003e\n        \u003cp\u003e\u003c/p\u003e\n        \u003cp style=\"color: #856a5d;\"\u003e\u003c/p\u003e\n      \u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003ctd style=\"background-color: #F5F5F5; border-color: #C7CDD1;\"\u003e使用言語\u003c/td\u003e\n      \u003ctd style=\"border-color: #C7CDD1;\"\u003e日本語\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003ctd style=\"background-color: #F5F5F5; border-color: #C7CDD1;\"\u003e連絡先\u003c/td\u003e\n      \u003ctd style=\"border-color: #C7CDD1;\"\u003ekazu@sfc.keio.ac.jp\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003ctd style=\"background-color: #F5F5F5; border-color: #C7CDD1;\"\u003e授業ホームページ\u003c/td\u003e\n      \u003ctd style=\"border-color: #C7CDD1;\"\u003ehttps://www.ht.sfc.keio.ac.jp/srobot\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003ctd style=\"background-color: #F5F5F5; border-color: #C7CDD1;\"\u003e設置学部・研究科\u003c/td\u003e\n      \u003ctd style=\"border-color: #C7CDD1;\"\u003e総合政策・環境情報学部\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003ctd style=\"background-color: #F5F5F5; border-color: #C7CDD1;\"\u003e大学院プロジェクト名\u003c/td\u003e\n      \u003ctd style=\"border-color: #C7CDD1;\"\u003e\u003cp\u003e\u003c/p\u003e\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003ctd style=\"background-color: #F5F5F5; border-color: #C7CDD1;\"\u003e大学院プロジェクトサブメンバー\u003c/td\u003e\n      \u003ctd style=\"border-color: #C7CDD1;\"\u003e\n        \u003cp\u003e\u003c/p\u003e\n        \u003cp style=\"color: #856a5d;\"\u003e\u003c/p\u003e\n      \u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003ctd style=\"background-color: #F5F5F5; border-color: #C7CDD1;\"\u003eゲストスピーカーの人数\u003c/td\u003e\n      \u003ctd style=\"border-color: #C7CDD1;\"\u003e\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003ctd style=\"background-color: #F5F5F5; border-color: #C7CDD1;\"\u003e履修選抜・課題タイプ=テキスト登録可\u003c/td\u003e\n      \u003ctd style=\"border-color: #C7CDD1;\"\u003efalse\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003ctd style=\"background-color: #F5F5F5; border-color: #C7CDD1;\"\u003e履修選抜・選抜課題タイプ=ファイル登録可\u003c/td\u003e\n      \u003ctd style=\"border-color: #C7CDD1;\"\u003efalse\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003ctd style=\"background-color: #F5F5F5; border-color: #C7CDD1;\"\u003eGIGAサティフィケート対象\u003c/td\u003e\n      \u003ctd style=\"border-color: #C7CDD1;\"\u003e\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003ctd style=\"background-color: #F5F5F5; border-color: #C7CDD1;\"\u003e最終更新日\u003c/td\u003e\n      \u003ctd style=\"border-color: #C7CDD1;\"\u003e2020/07/08 10:32:17\u003c/td\u003e\n    \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\n  \u003ch3 style=\"background-color: #394B58; color: white; padding-left: 8px; margin-bottom: 0; font-weight: bold;\"\u003eAdditional Information about language support on this course\u003c/h3\u003e\n  \u003ch4 style=\"color: #223377; font-weight: bold;\"\u003eLanguage used in each of the course components\u003c/h4\u003e\n  \u003ctable style=\"width: 100%; margin: 0; border-collapse: collapse; border: 1px solid #C7CDD1;\" border=\"1\"\u003e\n    \u003ctbody\u003e\n      \u003ctr\u003e\n        \u003ctd style=\"width: 20%; background-color: #F5F5F5; border-color: #C7CDD1;\"\u003eLecture\u003c/td\u003e\n        \u003ctd style=\"border-color: #C7CDD1;\"\u003e\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n        \u003ctd style=\"background-color: #F5F5F5; border-color: #C7CDD1;\"\u003eMaterial\u003c/td\u003e\n        \u003ctd style=\"border-color: #C7CDD1;\"\u003eBoth (English and Japanese)\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n        \u003ctd style=\"background-color: #F5F5F5; border-color: #C7CDD1;\"\u003eDiscussion\u003c/td\u003e\n        \u003ctd style=\"border-color: #C7CDD1;\"\u003eMainly English\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n        \u003ctd style=\"background-color: #F5F5F5; border-color: #C7CDD1;\"\u003eGroup work\u003c/td\u003e\n        \u003ctd style=\"border-color: #C7CDD1;\"\u003eEnglish or Japanese based on the students’ preference\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n        \u003ctd style=\"background-color: #F5F5F5; border-color: #C7CDD1;\"\u003ePresentation\u003c/td\u003e\n        \u003ctd style=\"border-color: #C7CDD1;\"\u003eBoth (English and Japanese)\u003c/td\u003e\n      \u003c/tr\u003e\n    \u003c/tbody\u003e\n  \u003c/table\u003e\n\n  \u003cp\u003e\u003c/p\u003e\n\n  \u003ch4 style=\"color: #223377; font-weight: bold;\"\u003eLevel of Japanese language skill necessary for the course\u003c/h4\u003e\n  \u003ctable style=\"width: 100%; margin: 0; border-collapse: collapse; border: 1px solid #C7CDD1;\" border=\"1\"\u003e\n    \u003ctbody\u003e\n      \u003ctr\u003e\n        \u003ctd style=\"width: 20%; background-color: #F5F5F5; border-color: #C7CDD1;\"\u003eReading\u003c/td\u003e\n        \u003ctd style=\"border-color: #C7CDD1;\"\u003eNot necessary. There will be no problems without any Japanese language skill.\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n        \u003ctd style=\"background-color: #F5F5F5; border-color: #C7CDD1;\"\u003eWriting\u003c/td\u003e\n        \u003ctd style=\"border-color: #C7CDD1;\"\u003eNot necessary. There will be no problems without any Japanese language skill.\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n        \u003ctd style=\"background-color: #F5F5F5; border-color: #C7CDD1;\"\u003eSpeaking\u003c/td\u003e\n        \u003ctd style=\"border-color: #C7CDD1;\"\u003eNot necessary. There will be no problems without any Japanese language skill.\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n        \u003ctd style=\"background-color: #F5F5F5; border-color: #C7CDD1;\"\u003eListnening\u003c/td\u003e\n        \u003ctd style=\"border-color: #C7CDD1;\"\u003eNot necessary. There will be no problems without any Japanese language skill.\u003c/td\u003e\n      \u003c/tr\u003e\n    \u003c/tbody\u003e\n  \u003c/table\u003e\n\n  \u003cp\u003e\u003c/p\u003e\n  \u003cp\u003e\u003c/p\u003e\n\n  \u003ch4 style=\"color: #223377; font-weight: bold;\"\u003eOther\u003c/h4\u003e\n\n  \u003cp\u003e\u003c/p\u003e\n\n\u003ch3 style=\"background-color: #394B58; color: white; padding-left: 8px; margin-bottom: 0; font-weight: bold;\"\u003e研究会概要\u003c/h3\u003e\n\u003ch4 style=\"background-color: #ccecff; padding-left: 8px; margin-top: 0; font-weight: bold;\"\u003e目的・内容\u003c/h4\u003e\n\u003cp\u003e*ソーシャルな存在としてのロボット*\u003cbr\u003e\u003cbr\u003e/\"Making robots more acceptable..\" by Prof. Gordon Cheng（ICS／TUM）/\u003cbr\u003e\u003cbr\u003e常時ネットワークに接続された次世代のロボットは，自ら M2M（Machine to Machine）コミュニケーション，M2S（Machine to Service）コミュニケーションを駆使する存在として，あるものはユビキタス情報サービスのアクターとして人々と共存し，またあるものは人の身体拡張を支援する，より社会的な存在となります．我々はこうしたロボットをソーシャブルロボット（Sociable Robot）と呼びます．社会性を備えたロボット，すなわち，ロボット同士，機械，情報サービス，そして人と能動的に繋がるロボットです．ソーシャブルロボットには，次のような機能が求められます．\u003cbr\u003e\u003cbr\u003e - 異種ロボット間のクラウド型協調・連携機能（Cloud Network Robotics）\u003cbr\u003e\u003cbr\u003e - 生体神経網と同等の高精度知覚・認知処理機能（Sentient \u0026amp; Cognitive Robotics）\u003cbr\u003e\u003cbr\u003e - 豊かな表情での社会的・情動的インタラクション機能（Affective \u0026amp; Interactive Robotics）\u003cbr\u003e\u003cbr\u003e第一の要件「クラウド型協調・連携」は言わば，ヘテロジニアスなロボット間連携・協調動作を実現するアーキテクチャです．多種多様なロボットのそれぞれが提供可能なサービスに関する情報を相互に共有することで，タスクに応じたコミュニティを自律的かつ臨機応変に形成し，様々なクラウドサービスとも連携しながら，ゴールの達成を目指します．本研究プロジェクトでは，ソーシャブルロボットの基本機能として適用可能な，異種ロボット同士，さらには多種多様な情報サービスとのクラウド型協調・連携を可能にするクラウドネットワークロボット間連携フレームワークを開発します．\u003cbr\u003e\u003cbr\u003e高度な社会性（Sociality）を備えたロボットにとって，ロボット自身が持つ知覚・認知能力は，人とのインタラクションの中でロボットの所作を決定する重要なファクターになります．第二の要件「高精度知覚・認知処理」に関しては，TUM / ICSでの Hex-o-Skin プロジェクトとの共同研究プロジェクトが進行中です．TUM / ICS Hex-o-Skin プロジェクトで開発が進むパッド型人工皮膚は，高度にモジュール化されており，皮下受容細胞に相当する触感センサ（近接，直接の2種），温感センサ，さらには運動感覚，平衡感覚を受容する高精度な動きセンサを備え，複数のパッドを連接して使用することで，人間の皮膚に近いレベルでの実世界情報収集と状況認識を可能としています．本研究プロジェクトでは，これらの皮膚感覚に加え，人とロボット（H2R）のインタラクションにおけるロボットの知覚・認知処理の中でも特に重要と考えられる，視覚（画像知覚・認知）に着目し，視覚による対話相手の情動取得，すなわち人の感情変化の取得機構を議論します．\u003cbr\u003e\u003cbr\u003e対話相手の情動認識機能は，第三の要件「社会的・情動的インタラクション」の実現に不可欠なものです．本研究プロジェクトでは，TUM / ICS のチームと共同で，生体神経網をモデルとしたスケーラブルな知覚神経ネットワークおよび認知機能を研究・開発します．他のロボットとの情報共有や，情動取得に関する視覚からのアプローチと併せて，センサクラウドとの連携も可能な，ソーシャブルロボット広域知覚神経網・認知システムとしての完成を目指しています．\u003cbr\u003e\u003cbr\u003eさらに第三の要件「社会的・情動的インタラクション」に関しては，情動を含む周囲と相手の状況を理解した上での，多対多 H2R，さらには R2R（ロボット同士）インタラクションの実現手法を議論します．私たちはこれまでにも，「共感するロボット」「遠隔アイスブレーキング支援ロボット」等を実装し，様々な利用シーンでの多対多 R2H インタラクションを例示してきましたが，本研究プロジェクトでは，多対多 R2H インタラクションの実現に向けた会話コンテクスト管理・制御機構を提案し，情動的インタラクション実現の一例として，上述の視覚による情動認識機構を応用した，会話の中での身体的表現力増強ロボットの提案を目指します．\u003cbr\u003e\u003cbr\u003e---\u003cbr\u003e\u003cbr\u003e*IoT から Sociable Things の世界へ*\u003cbr\u003e\u003cbr\u003e前述のヒューマノイド型のコミュニケーションロボットやパーソナルロボットをターゲットとして提案した技術を，より細粒度なモノやロボットに適用することで，次世代IoT環境の構築が可能となります．私たちはこれを，Sociable Things と呼んでいます．個々の Sociable Thing が高機能である必要はありません．ユーザの挙動や情動を理解し，共有し，それぞれのモノとしての機能を少しだけユーザに寄り添う形で提供する，そんなモノたちのコミュニティです．\u003cbr\u003e\u003cbr\u003eモノがソーシャブルたり得る要件の1つに，人同士のインタラクションで日常的に見られる，多面的，多段的なインタラクション「駆け引き」があります．駆け引きという行為により，Sociable Thingsには，人に物理的に働きかけて関心を引き，次に行うべき行為に誘導するといった，より柔軟なインタラクションを繰り返し行うことを可能とする力があります．例えば，ソーシャブルなゴミ箱（Sociable Trashbox）は，ゴミを投げようとしているユーザを検知し，その方向に筐体を傾けます．ゴミを捨てようとしているユーザを発見し，自ら近づいて行ってもいいでしょう．物体の移動は人間の注意を引きますし，物体が傾く動作は人間における感謝を表すための「会釈」というボディランゲージに似ているとも言えます．ユーザが子どもであれば，子どもたちはゴミ箱そのものの動きに関心を寄せるでしょうし，会釈のように見える動作には愛着を覚えることもあるでしょう．結果として，「見逃されがちなゴミ箱やゴミを捨てるという行為に興味や楽しさを覚える」といった，意識の変化を見ることができるかもしれません．人々とのインタラクションの中で，それぞれの状況認識（センシング）機能，アクチュエーション機能を生かし，モノ同士が協調して駆け引きを行い，人に対しては効果的かつ身体的な学びを促し，同時にサービスとしての妥協点を探る．Sociable Things には，そんなインタラクションの未来があります．\u003cbr\u003e\u003cbr\u003eソーシャブルなロボットの次のステップとしての，ソーシャブルなモノ（Sociable Things）は，意義のある研究領域であり，有力な候補です．ロボットの実装やそれに対する利便性というロボット工学的なアプローチだけでなく，行動変容などの認知心理学的，医療的議論も必要な，学際的研究テーマとなるでしょう．既に，ユーザの疲労を検知してアクションを起こす「ワークライフバランスキーボード」や，モノたちが連携してユーザと駆け引きを行う「ダイエット支援サービス」をはじめとする，いくつかの関連プロジェクトがスタートしていますが，今後のさらなる研究的発展が期待されています．\u003cbr\u003e\u003cbr\u003e---\u003cbr\u003e\u003cbr\u003e*各自が得意の分野でエキスパートに*\u003cbr\u003e\u003cbr\u003e研究会では，大学院プロジェクト（ユビキタスコンピューティング\u0026amp;ネットワーキングプロジェクト）とも連携し，調査，グループディスカッションといった研究活動を通して，論点の洗い出しを行い，メンバ個々に問題を設定，それらを解決するための手法を探ります．\u003cbr\u003e\u003cbr\u003e各メンバには，学期中にこれら一連のサイクルを経験してもらいますが，特に，キャンパスや関係協力機関での実装・検証実験の経験を積むことで，実証的な議論の姿勢と，システム開発に必要な様々なスキルを学んでもらいます．\u003cbr\u003e\u003cbr\u003e加えて，研究会のメンバには，1人1人が何かしらのエキスパートになってほしいと考えています．電子工作のエキスパート，特定のマイコンのエキスパート，機械工作のエキスパート，3D モデリングのエキスパート，機械学習のエキスパート，画像認識のエキスパート，制御系プログラミングのエキスパート等々，なんでも構いません．研究会活動の中で，各メンバが自分の得意分野を伸ばすだけでなく，メンバ同士がその得意分野をレクチャーし合うことでお互いのスキルアップを目指します．そのため，各自がテーマを設定し講師となるスキルアップセミナを，学期中に1回は開催してもらいます．\u003cbr\u003e\u003cbr\u003e---\u003cbr\u003e\u003cbr\u003e*■ 感じるロボット／気付くロボット・・プロジェクト*\u003cbr\u003e\u003cbr\u003e - exo-NeuroNet： 行動意図に応じてアドホックに構築可能なロボットのための外部神経網\u003cbr\u003e\u003cbr\u003e - 水中状況認識を可能とする水中パッシブセンサモジュール（水中ロボットのための人工スキン）\u003cbr\u003e\u003cbr\u003e - 中高等教育向け STEM ロボットキット “そしゃぼっと”（仮）\u003cbr\u003e\u003cbr\u003e - ユーザと場の共有をする AR エージェント\u003cbr\u003e\u003cbr\u003e*■ Sociable Things／やわらかい機械／ゆるいロボット・・プロジェクト*\u003cbr\u003e\u003cbr\u003e - Metamorphic Cloudbot： クラウド・ロボティックス・アーキテクチャをベースにしたパーソナル・ロボット・フレームワーク \u003cbr\u003e\u003cbr\u003e - 「駆け引き」のできるモノたちとのインタラクション\u003cbr\u003e\u003cbr\u003e - 空中浮遊型ゆるふわロボット\u003cbr\u003e\u003cbr\u003e - 悶える自動改札\u003cbr\u003e\u003cbr\u003e*■ 繋がるロボット／伝えるロボット・・プロジェクト*\u003cbr\u003e\u003cbr\u003e - 多対多 R2H コミュニケーションのための特定話者認識と追跡手法\u003cbr\u003e\u003cbr\u003e - 多対多 R2H コミュニケーションにおける会話コンテクスト制御\u003cbr\u003e\u003cbr\u003e - 多対多 R2H インタラクションのためのネットワークリソースを活用した話題生成機構\u003cbr\u003e\u003cbr\u003e - 多対多 R2H インタラクションにおけるパーソナル・スペース分析 〜Pepper に壁ドンはできるか〜\u003cbr\u003e\u003cbr\u003e - 一期一会 〜HRRH 遠隔アイスブレーキング〜\u003cbr\u003e\u003cbr\u003e - Symonds 尺度を用いたロボットのパーソナリティ発達\u003cbr\u003e\u003cbr\u003e*■ ロボットとヒトの協調／ヒトの身体拡張・・プロジェクト*\u003cbr\u003e\u003cbr\u003e - Ex-Amp Robot: Expressive Robotic Avatar with Multimodal Emotion Detection to Enhance Communication of Users with Motor Disabilities\u003cbr\u003e\u003cbr\u003e - 2.5次元 H2R インタラクション\u003cbr\u003e\u003cbr\u003e - 人との間に適切な間合いを生み出すロボット\u003cbr\u003e\u003cbr\u003e - メンタルサインを考慮した人間とロボットのインタラクション\u003cbr\u003e\u003cbr\u003e - アイコンタクトによるロボットと人の協調動作\u003cbr\u003e\u003cbr\u003e - ロボットの感覚を伝える装着型感覚ディスプレイ\u003cbr\u003e\u003cbr\u003e - exo-NeuroNet による生体神経網の空間的拡張と論理的身体感覚形成（Logical Body）\u003c/p\u003e\n\u003cp style=\"color: #856a5d;\"\u003e---\u003cbr\u003e\u003cbr\u003e*Social Interaction with Cloud Network Robots*\u003cbr\u003e\u003cbr\u003e/“Making robots more acceptable..”/\u003cbr\u003e\u003cbr\u003eis the words of Professor Gordon Chen who leads ICS (Institute for Cognitive System) at Technische Universität München (TUM). What exactly is a robot that does not give discomfort to us and we can easily accept its existence as a part of everyday life?\u003cbr\u003eNow we obtain capabilities to access ubiquitous information spaces and our human ability and cognitive performance will be gradually enhanced. Robots will also be integrated well into the human life and helping us naturally. They will have rich sensory perception and expressive facial signals, and are going to be social partners for us. In this laboratory, we are discussing what kind of “sociality” robots should have in human robot interactions (HRI).\u003cbr\u003e\u003cbr\u003eBeing human, the behaviors with “sociality” will have an important meaning. Like communication skill to understand or sympathize with others, skill to recognize multiple contexts at the same time correctly and skill to create moderate intervals with interaction partners, ability to ensure social performance is various. Robots, and even everyday things, are also similar. An information system or a robot which has advanced interpersonal communication skill, can show correct judgement in all circumstances and be able to cooperate with people, robots, everyday things and various information services, such existence is probably an “acceptable” information system or robot.\u003cbr\u003e\u003cbr\u003eRobots are interactive interfaces in real-world between users and ubiquitous information services. If the robot technology advances and many of objects in our everyday life are robotized, the cooperative world with such novel things “next generation IoT” will be opened. We call robots and IoT devices which provide a certain kind of sociality “Sociable Robots” and “Sociable Things”.\u003cbr\u003e\u003cbr\u003eRobots that work as an edge terminals of cloud services are called a “Cloud Network Robots”. The architecture of the Cloud Network Robots which realizes cooperative operations among heterogeneous robots can be the base of Sociable Robots and Sociable Things. A wide variety of robots aim at achieving their goals while sharing information on services that each can provide, autonomously and adaptively forming communities corresponding to tasks they are faced with, and working together with various cloud services. Some of them will coexist with us as actors of ubiquitous and cloud information services and some will argument our human ability by making full use of M2M (Machine to Machine) communication and M2S (Machine to Service) communication.\u003cbr\u003e\u003cbr\u003eThe Cloud Network Robots are beginning to be implemented in various forms such as agent software on information devices like smart phones, communication robots, and personal mobility robots such as wheelchairs and EV vehicles. The technical issues of Cloud Network Robot are as follows.\u003cbr\u003e\u003cbr\u003e - Cooperation and collaboration technologies among heterogeneous robots\u003cbr\u003e\u003cbr\u003e - Data linkage technologies between robot and cloud information service\u003cbr\u003e\u003cbr\u003e - Many-to-many human robot interaction technologies\u003cbr\u003e\u003cbr\u003eIn addition to these issues, we are discussing the following two more issues for Sociable Robots.\u003cbr\u003e\u003cbr\u003e - Highly accurate perceptual processing and context recognition technologies for HRI\u003cbr\u003e\u003cbr\u003e - Social and affective interaction technologies in HRI\u003cbr\u003e\u003cbr\u003eFrom the viewpoint of the sociality, the perception and context capturing function possessed by robots themselves is an important factor in determining behaviors of robots in human interactions. We are focusing attention on the emotional recognition of the communication partner, that is, the acquisition mechanism of human’s emotional changes, which is indispensable for realizing “social and emotional interaction”, and have been exemplifying its principles, implementation methods, and application examples. We have exemplified many-to-many human robot interactions in various usage scenes by implementing “sympathizing robot”, “remote ice breaking robot system”, etc. Topics covered in this lab range over “pseudo-emotional behaviors of robot in HRI”, “the personality of robot naturally being built by HRI”, “creating moderate interval and proximity in HRI” and so on. They are examples of next generation social and emotional human robot interactions.\u003cbr\u003e\u003cbr\u003e---\u003cbr\u003e\u003cbr\u003e*Topics in detail*\u003cbr\u003e\u003cbr\u003e - Cloud Network Robotics\u003cbr\u003e\u003cbr\u003e  - Robots active at the edge of services\u003cbr\u003e\u003cbr\u003e  - Raising robots with cloud AI\u003cbr\u003e\u003cbr\u003e  - Creating robot community\u003cbr\u003e\u003cbr\u003e  - The changes in human robot interaction\u003cbr\u003e\u003cbr\u003e - Robots who began to have Physical Characteristics\u003cbr\u003e\u003cbr\u003e  - Robot design in first person viewpoint\u003cbr\u003e\u003cbr\u003e  - Understanding what’s going on around itself\u003cbr\u003e\u003cbr\u003e  - Understanding the partner’s emotions and intentions\u003cbr\u003e\u003cbr\u003e  - Robot that began to have feelings\u003cbr\u003e\u003cbr\u003e  - Can people sympathize with robots?\u003cbr\u003e\u003cbr\u003e - Robots acting Social - Sociable Robots -\u003cbr\u003e\u003cbr\u003e  - Eleven requirements for sociality\u003cbr\u003e\u003cbr\u003e  - Understanding the flow of conversation - conversation context management -\u003cbr\u003e\u003cbr\u003e  - Management the interval and the proximity in HRI\u003cbr\u003e\u003cbr\u003e  - Interaction fosters robot’s personality\u003cbr\u003e\u003cbr\u003e  - Robots supporting human to human communication\u003cbr\u003e\u003cbr\u003e  - Practice in the nursing care field\u003c/p\u003e\n\n\u003ch4 style=\"background-color: #ccecff; padding-left: 8px; font-weight: bold;\"\u003e評価方法\u003c/h4\u003e\n\u003cp\u003e出席，研究会への貢献，タームプロジェクト（学期を通してのシステム等の構築）成果物，各マイルストーンでのプレゼンテーション・デモンストレーションを総合して評価します．\u003c/p\u003e\n\u003cp style=\"color: #856a5d;\"\u003e---\u003cbr\u003e\u003cbr\u003eBoth of contributions for our lab and term project outputs including presentations and demonstrations will be evaluated.\u003c/p\u003e\n\n\u003ch4 style=\"background-color: #ccecff; padding-left: 8px; font-weight: bold;\"\u003e教材・参考文献\u003c/h4\u003e\n\u003cp\u003e - Lab. Leaflet (PDF) ( [https://www.ht.sfc.keio.ac.jp/pamphlet2015_final_mini.pdf] )\u003cbr\u003e - ICS (Institute for Cognitive Systems) TUM ( [http://www.ics.ei.tum.de] )\u003cbr\u003e - その他，研究会ホームページの Projects and Publications を参照のこと\u003c/p\u003e\n\n\u003ch4 style=\"background-color: #ccecff; padding-left: 8px; font-weight: bold;\"\u003e関連プロジェクト\u003c/h4\u003e\n\u003cp\u003e総務省 CUBIQ プロジェクト，JST CREST OSOITE プロジェクト，JST CREST DEOS プロジェクト，EU-Japan Clou-T プロジェクト，他\u003c/p\u003e\n\u003cp style=\"color: #856a5d;\"\u003e---\u003cbr\u003e\u003cbr\u003eMIC CUBIQ Project, JST CREST OSOITE Project, JST CREST DEOS Project, EU-Japan Clou-T Project and others\u003c/p\u003e\n\n\u003ch4 style=\"background-color: #ccecff; padding-left: 8px; font-weight: bold;\"\u003e課題\u003c/h4\u003e\n\u003cp\u003e\u003c/p\u003e\n\u003cp style=\"color: #856a5d;\"\u003e\u003c/p\u003e\n\n\u003ch4 style=\"background-color: #ccecff; padding-left: 8px; font-weight: bold;\"\u003e来期の研究プロジェクトのテーマ予定\u003c/h4\u003e\n\u003cp\u003eソーシャブルなモノ，ロボット，情報空間の構成法\u003c/p\u003e\n\u003cp style=\"color: #856a5d;\"\u003e---\u003cbr\u003e\u003cbr\u003eSociable Things, Robots and Information Services\u003c/p\u003e\n\n\u003ch4 style=\"background-color: #ccecff; padding-left: 8px; font-weight: bold;\"\u003eその他・留意事項\u003c/h4\u003e\n\u003cp\u003e履修希望者は，必ず事前に（学期開始前なるべく春学期中に）メールで連絡，または適宜，オンラインで高汐を捕まえてください．\u003c/p\u003e\n\u003cp style=\"color: #856a5d;\"\u003e---\u003cbr\u003e\u003cbr\u003eStudents who want to join our lab should contact me by e-mail before the semester will start.\u003c/p\u003e\n\n\u003ch4 style=\"background-color: #ccecff; padding-left: 8px; font-weight: bold;\"\u003e授業スケジュール\u003c/h4\u003e\n\u003cp\u003e\u003c/p\u003e\n\u003cp style=\"color: #856a5d;\"\u003e\u003c/p\u003e\n","course_code":"研究会Ａ","default_view":"modules","root_account_id":1,"enrollment_term_id":3,"license":null,"grade_passback_setting":null,"end_at":null,"public_syllabus":false,"public_syllabus_to_auth":true,"storage_quota_mb":30000,"is_public_to_auth_users":true,"term":{"id":3,"name":"2020年秋学期","start_at":null,"end_at":null,"created_at":"2020-09-03T21:25:41Z","workflow_state":"active","grading_period_group_id":null},"apply_assignment_group_weights":false,"calendar":{"ics":"https://sol.sfc.keio.ac.jp/feeds/calendars/course_oDeoUqBjQOT55IRatrIoE1A6AO1GNJasJT1UR5tV.ics"},"time_zone":"Asia/Tokyo","blueprint":false,"enrollments":[],"hide_final_grades":false,"workflow_state":"available","restrict_enrollments_to_course_dates":false,"overridden_course_visibility":""}